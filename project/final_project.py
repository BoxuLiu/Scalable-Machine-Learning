# -*- coding: utf-8 -*-
"""Final_Project_Task_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZONhEDK6PJfIAeqN5KOqtAQXTmUIzBwe
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install torchnet

import os
import torch
import torch.nn as nn
import torchvision as tv
from torch.autograd import Variable
import tqdm
import matplotlib.pyplot as plt
from torchnet.meter import AverageValueMeter
plt.rcParams['font.sans-serif'] = ['SimHei']  
plt.rcParams['axes.unicode_minus'] = False

dir = '/content/drive/MyDrive/GAN/data/'

noiseSize = 100    
n_generator_feature = 64       
n_discriminator_feature = 64       
d_every = 1    
g_every = 5   
save_every = 10 


class NetGenerator(nn.Module):
    def __init__(self):
        super(NetGenerator,self).__init__()
        self.main = nn.Sequential(     
            nn.ConvTranspose2d(noiseSize, n_generator_feature * 8, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(n_generator_feature * 8),
            nn.ReLU(True),      
            nn.ConvTranspose2d(n_generator_feature * 8, n_generator_feature * 4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n_generator_feature * 4),
            nn.ReLU(True),     
            nn.ConvTranspose2d(n_generator_feature * 4, n_generator_feature * 2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n_generator_feature * 2),
            nn.ReLU(True), 
            nn.ConvTranspose2d(n_generator_feature * 2, n_generator_feature, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n_generator_feature),
            nn.ReLU(True),     
            nn.ConvTranspose2d(n_generator_feature, 3, kernel_size=5, stride=3, padding=1, bias=False),
            nn.Tanh()      
        )

    def forward(self, input):
        return self.main(input)


class NetDiscriminator(nn.Module):
    def __init__(self):
        super(NetDiscriminator,self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, n_discriminator_feature, kernel_size=5, stride=3, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),       
            nn.Conv2d(n_discriminator_feature, n_discriminator_feature * 2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n_discriminator_feature * 2),
            nn.LeakyReLU(0.2, inplace=True),         
            nn.Conv2d(n_discriminator_feature * 2, n_discriminator_feature * 4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n_discriminator_feature * 4),
            nn.LeakyReLU(0.2, inplace=True), 
            nn.Conv2d(n_discriminator_feature * 4, n_discriminator_feature * 8, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n_discriminator_feature * 8),
            nn.LeakyReLU(0.2, inplace=True),  
            nn.Conv2d(n_discriminator_feature * 8, 1, kernel_size=4, stride=1, padding=0, bias=False),
            nn.Sigmoid()       
        )

    def forward(self, input):
        return self.main(input).view(-1)


def train():
    for i, (image,_) in tqdm.tqdm(enumerate(dataloader)):      
        real_image = Variable(image)
        real_image = real_image.cuda()

        if (i + 1) % d_every == 0:
            optimizer_d.zero_grad()
            output = Discriminator(real_image)      
            error_d_real = criterion(output, true_labels)
            error_d_real.backward()

            noises.data.copy_(torch.randn(batch_size, noiseSize, 1, 1))
            fake_img = Generator(noises).detach()      
            fake_output = Discriminator(fake_img)      
            error_d_fake = criterion(fake_output, fake_labels)
            error_d_fake.backward()
            optimizer_d.step()

        if (i + 1) % g_every == 0:
            optimizer_g.zero_grad()
            noises.data.copy_(torch.randn(batch_size, noiseSize, 1, 1))
            fake_img = Generator(noises)        
            fake_output = Discriminator(fake_img)      
            error_g = criterion(fake_output, true_labels)
            error_g.backward()
            optimizer_g.step()


def show(num):
    fix_fake_imags = Generator(fix_noises)
    fix_fake_imags = fix_fake_imags.data.cpu()[:64] * 0.5 + 0.5
    fig = plt.figure(1)

    i = 1
    for image in fix_fake_imags:
        ax = fig.add_subplot(8, 8, eval('%d' % i))
        plt.axis('off')
        plt.imshow(image.permute(1, 2, 0))
        i += 1
    plt.subplots_adjust(left=None,  
                        right=None,  
                        bottom=None,  
                        top=None, 
                        wspace=0.05,  
                        hspace=0.05)  
    plt.suptitle('%dth result' % num, y=0.91, fontsize=15)
    plt.show()

torch.device("cuda" if torch.cuda.is_available() else "cpu")
print((torch.device("cuda" if torch.cuda.is_available() else "cpu")))

Generator = NetGenerator()
Discriminator = NetDiscriminator()

optimizer_g = torch.optim.Adam(Generator.parameters(), lr=2e-4, betas=(0.5, 0.999))
optimizer_d = torch.optim.Adam(Discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))
criterion = torch.nn.BCELoss()

true_labels = Variable(torch.ones(batch_size))    
fake_labels = Variable(torch.zeros(batch_size))
fix_noises = Variable(torch.randn(batch_size, noiseSize, 1, 1))
noises = Variable(torch.randn(batch_size, noiseSize, 1, 1))    

if torch.cuda.is_available() == True:
    print('Cuda is available!')
    Generator.cuda()
    Discriminator.cuda()
    criterion.cuda()
    true_labels, fake_labels = true_labels.cuda(), fake_labels.cuda()
    fix_noises, noises = fix_noises.cuda(), noises.cuda()

errord_meter = AverageValueMeter()
errorg_meter = AverageValueMeter()

transform = tv.transforms.Compose([
    tv.transforms.Resize(96),     
    tv.transforms.CenterCrop(96),
    tv.transforms.ToTensor(),
    tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))       
])

dataset = tv.datasets.ImageFolder(dir, transform=transform)

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)  

print('Dataset loaded')

plot_epoch = [1,5,10,20,50,100,199,299,399,499]

for i in range(500):        # max epoch
    train()

    if (i + 1) % save_every == 0:
      torch.save(Discriminator.state_dict(), '/content/drive/MyDrive/GAN/model/netd_%s.pth' % i)
      torch.save(Generator.state_dict(), '/content/drive/MyDrive/GAN/model/netg_%s.pth' % i)
      errord_meter.reset()
      errorg_meter.reset()

    print('epochï¼š{}'.format(i))
    if i in plot_epoch:
        show(i)

device=torch.device('cuda')

noises = torch.randn(512, 100, 1, 1).normal_(0, 1)
noises = noises.to(device)

map_location = lambda storage, loc: storage
Discriminator.load_state_dict(torch.load('/content/drive/MyDrive/GAN/model/netd_499.pth', map_location=map_location))
Generator.load_state_dict(torch.load('/content/drive/MyDrive/GAN/model/netg_499.pth', map_location=map_location))
Discriminator.to(device)
Generator.to(device)

fake_imags = Generator(noises)
fake_imags = fake_imags.data.cpu()[:64] * 0.5 + 0.5

fig = plt.figure(1)

i = 1
for image in fake_imags:
#    ax = fig.add_subplot(8, 8, eval('%d' % i))
    plt.axis('off')
    plt.imshow(image.permute(1, 2, 0))
    i += 1
plt.subplots_adjust(left=None,  
                    right=None,  
                    bottom=None,  
                    top=None,  
                    wspace=0.05,  
                    hspace=0.05)  
plt.show()